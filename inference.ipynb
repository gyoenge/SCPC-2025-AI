{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration, BitsAndBytesConfig\n",
    "from peft import PeftModel, prepare_model_for_kbit_training\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "base_model_id = \"Salesforce/blip2-flan-t5-xl\"\n",
    "trained_model_id = \"./model/finetuned-bilp2-flan-t5-xl\"\n",
    "\n",
    "# 4bit quantization for decoder only\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Load processor \n",
    "processor = Blip2Processor.from_pretrained(base_model_id, use_fast=True)\n",
    "\n",
    "# t5 model만 4bit로 Load\n",
    "t5 = T5ForConditionalGeneration.from_pretrained(\n",
    "    \"google/flan-t5-xl\",  # BLIP2가 내부적으로 사용하는 T5 모델\n",
    "    device_map=\"auto\",\n",
    "    # device_map={\"\": 0},  # 모든 모듈을 GPU 0번으로\n",
    "    quantization_config=quantization_config\n",
    ")\n",
    " \n",
    "# BLIP2 모델을 float32로 로딩\n",
    "model_fp = Blip2ForConditionalGeneration.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    # device_map={\"\": 0},  # 모든 모듈을 GPU 0번으로\n",
    ")\n",
    "\n",
    "# decoder만 4bit T5로 교체\n",
    "model_fp.language_model = t5\n",
    "\n",
    "# LoRA fine-tuned weight 적용\n",
    "model = PeftModel.from_pretrained(model_fp, trained_model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e196920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total Parameters: {total_params:,}\")\n",
    "    print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "\n",
    "count_parameters(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ca218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setting\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd84709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for extracting answer letter [A/B/C/D]\n",
    "def extract_answer_letter(text):\n",
    "    # match = re.search(r\"Answer:\\s*([A-Da-d])\\b\", text)\n",
    "    match = re.search(r\"\\b([A-D])\\b\", text)\n",
    "    return match.group(1).upper() if match else \"?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf2dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_dir = './dataset/given/'\n",
    "test = pd.read_csv(os.path.join(test_dataset_dir, 'test.csv'))\n",
    "results = []\n",
    "\n",
    "for i, row in tqdm(test.iterrows(), total=len(test)):\n",
    "    image = Image.open(os.path.join(test_dataset_dir, row['img_path'])).convert(\"RGB\")\n",
    "\n",
    "    ### Step 1: Description 생성 ###\n",
    "    desc_prompt = (\n",
    "        \"USER: Based on the image and question, write a description.\\n\"\n",
    "        f\"Question: {row['Question']}\\n\\n\"\n",
    "        \"Description:\\n\"\n",
    "        \"ASSISTANT:\"\n",
    "    )\n",
    "\n",
    "    inputs = processor(images=image, text=desc_prompt, return_tensors=\"pt\")\n",
    "    inputs = {k: (v.half().to(device) if v.dtype == torch.float32 else v.to(device)) for k, v in inputs.items()}\n",
    "\n",
    "    output = model.generate(**inputs, max_new_tokens=128, do_sample=False) #, temperature=0.0)\n",
    "    generated_description = processor.tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    print(f\"\\n[Step 1] Generated Description: {generated_description}\")\n",
    "    \n",
    "    ### Step 2: 선택지 포함 프롬프트 구성 후 추론 ###\n",
    "    final_prompt = (\n",
    "        \"USER: Based on the image, description, and question, choose the best option from A, B, C, or D.\\n\"\n",
    "        f\"Description: {generated_description}\\n\"\n",
    "        f\"Question: {row['Question']}\\n\"\n",
    "        f\"A. {row['A']}\\n\"\n",
    "        f\"B. {row['B']}\\n\"\n",
    "        f\"C. {row['C']}\\n\"\n",
    "        f\"D. {row['D']}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "\n",
    "    inputs = processor(images=image, text=final_prompt, return_tensors=\"pt\")\n",
    "    inputs = {k: (v.half().to(device) if v.dtype == torch.float32 else v.to(device)) for k, v in inputs.items()}\n",
    "\n",
    "    output = model.generate(**inputs, max_new_tokens=3, do_sample=False) #, temperature=0.0)\n",
    "    decoded = processor.tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    print(f\"[Step 2] Final Answer Prediction: {decoded}\")\n",
    "    print(\"==========================================================\")\n",
    "\n",
    "\n",
    "    results.append(extract_answer_letter(decoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b80ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_base_file_path = './dataset/given/sample_submission.csv'\n",
    "submission_save_file_path = './test_inference_final.csv'\n",
    "\n",
    "submission = pd.read_csv(submission_base_file_path)\n",
    "submission['answer'] = results\n",
    "submission.to_csv(submission_save_file_path, index=False)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e43b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
